{"data":{"markdownRemark":{"html":"<p>에러가 나는게, <a href=\"https://docs.bitnami.com/google/apps/elasticsearch/get-started/understand-default-config/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">여기</a> 설명에 나온대로 elasticsearch log를 확인해 보니, jaso analyzer 관련 클래스인 <code class=\"language-text\">JasoTokenizerFactory</code>에서 <code class=\"language-text\">NoSuchMethod</code>에러가 나고 있었다. 들어가 코드를 확인해 보니, vscode에서 <code class=\"language-text\">super(...)</code>콜에서 매개변수가 안맞다며 빨간 줄이 쳐지고 quick fix를 하니 부모의 시그니쳐에 맞게 한 매개변수가 삭제되었다. 삭제하고 빌드해서 s3에 올리고 원래 설치된것 삭제하고 url로 다시 설치했는데 또 실패하길래 왜지 하다가 생각해보니 또 elasticsearch 서비스 재시작이 필요한 것이었다. 서비스 재시작을 하니 드디어 성공적으로 kengdic 인덱스를 만들었다. 아 그리고 매핑 타입이 없어졌다는걸 봐서 일단 'logs' 타입을 빼고 PUT 요청을 넣었다. 전에 쓰던 인덱스 세팅이 두 가지 있는데 뭐였는지 까먹었다. 아마도 아래꺼일듯.</p>\n<p>최종 요청 (아래꺼 씀.)</p>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\">PUT kengdic\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"analysis\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"nori-user-dict\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"decompound_mode\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"mixed\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"user_dictionary\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"userdict_ko.txt\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"analyzer-kor\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori-user-dict\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"analyzer-eng\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"lowercase\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    // <span class=\"token property\">\"logs\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"word\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-kor\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"def\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-eng\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    // <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\nPUT kengdic\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"analysis\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"suggest_filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"edge_ngram\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"min_gram\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"max_gram\"</span><span class=\"token operator\">:</span> <span class=\"token number\">50</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"nori-user-dict\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"decompound_mode\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"mixed\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"user_dictionary\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"userdict_ko.txt\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"jaso_search_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"jaso_index_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span>\n        <span class=\"token punctuation\">}</span>\n        // <span class=\"token property\">\"jaso_search_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        //   <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span>\n        // <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        // <span class=\"token property\">\"jaso_index_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        //   <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span>\n        // <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"analyzer-kor\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori-user-dict\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"analyzer-eng\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"lowercase\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"kor-suggest_search_analyzer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_search_tokenizer\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"kor-suggest_index_analyzer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_index_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"suggest_filter\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"logs\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"word\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"store\"</span><span class=\"token operator\">:</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"kor-suggest_index_analyzer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"search_analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"kor-suggest_search_analyzer\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"def\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-eng\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>그런데 데이터를 다 넣어도 <code class=\"language-text\">GET _stats</code>의 결과에서 kengdic의 document count가 0이길래 왜인가 싶어 로그를 확인했더니, <code class=\"language-text\">rejecting mapping update to as the final mapping would have more than 1 type [_doc, logs]</code> 이런 에러가 떴다. 생각해보니, elasticsearch 버전 7쯤에서 매핑 타입이 없어졌다지만, 나는 scoop으로 설치한 구버전 logstash를 그대로 쓰고있어서 type을 지정 안 하면 전처럼 <code class=\"language-text\">logs</code> 타입으로 기본으로 넣으려 한 것이다. 그래서 logstash 문서에서 찾아보니 elasticsearch output 플러그인에서는 <code class=\"language-text\">document_type</code>으로 지정하면 된다고 해서 <code class=\"language-text\">document_type=&gt;&quot;_doc&quot;</code>이렇게 하니 성공적으로 데이터가 들어가고 검색도 성공했다. 드디어!</p>\n<p>드디어 클러스터 전체를 테스트할 차례가 왔다. 문제는 어디 가거나 잘 때마다 이 전체 설정을 반복해야하는데.. bash 스크립트로 짜야 하려나?</p>\n<p>elasticsearch 서비스 생성 과정:</p>\n<ol>\n<li>elasticsearch cluster certified by bitnami를 배포.</li>\n<li>배포 완료되면 elasticsearch-vm에 접속</li>\n<li>vm에서 <code class=\"language-text\">jaso-analyzer</code>, <code class=\"language-text\">nori-analysis</code> 플러그인 설치. (<code class=\"language-text\">jaso-analyzer</code>는 aws s3에 올려놓고 퍼블릭으로 설정하면 주소로 바로 설치 가능.)</li>\n<li>vm에서 <code class=\"language-text\">sudo touch /opt/bitnami/elasticsearch/config/userdict_ko.txt</code> 로 사용자 사전 파일 생성</li>\n<li>vm에서 <code class=\"language-text\">sudo /opt/bitnami/ctlscript.sh restart elasticsearch</code>로 es 서비스 재시작(플러그인 로드)</li>\n<li>es 서비스가 재시작되었으면 <code class=\"language-text\">kengdic</code> 인덱스 생성하기.</li>\n<li>로컬에서 logstash의 elasticsearch output 필터의 <code class=\"language-text\">user</code>, <code class=\"language-text\">password</code> 항목을 위에서 생성한 클러스터의 정보를 참고하여 업데이트</li>\n<li><code class=\"language-text\">importDatas.ps1</code> 실행</li>\n</ol>\n<p>로컬과 구글 콘솔 gui와 원격 vm 환경이 조합되어있어 자동화가 어려워보인다.. gcp에서 현재 상태를 다시 docker image처럼 템플릿화해서 저장해둘 수 있으면 정말 좋겠다. </p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<p>  #vocabo, #elasticsearch</p>","fields":{"slug":"드디어-kengdic-index-생성-완료"},"frontmatter":{"title":"드디어!! kengdic index 생성 완료","date":"26.05.2019","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/3.jpg"},"timeToRead":2}},"pageContext":{"slug":"드디어-kengdic-index-생성-완료","prev":{"excerpt":"gh-pages로 블로그 올림.분명히 master 브랜치를 다 지웠는데도 계속  라는 에러가 떠서 왜그런가 했더니,  노드 모듈의 캐시에 저장되있어서였다. https://github.com/transitive-bullshit/react-modern-library-boilerplate/issues/15 여기에 나온대로 의 캐시를 지웠더니 잘 된다.tags  #blog, #github-pages","html":"<h3 id=\"gh-pages로-블로그-올림\"><a href=\"#gh-pages%EB%A1%9C-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EC%98%AC%EB%A6%BC\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>gh-pages로 블로그 올림.</h3>\n<p>분명히 master 브랜치를 다 지웠는데도 계속 <code class=\"language-text\">A branch named &#39;master&#39; already exists.</code> 라는 에러가 떠서 왜그런가 했더니, <code class=\"language-text\">gh-pages</code> 노드 모듈의 캐시에 저장되있어서였다. </p>\n<p><a href=\"https://github.com/transitive-bullshit/react-modern-library-boilerplate/issues/15\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/transitive-bullshit/react-modern-library-boilerplate/issues/15</a> 여기에 나온대로 <code class=\"language-text\">gh-pages</code>의 캐시를 지웠더니 잘 된다.</p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<p>  #blog, #github-pages</p>","id":"46dd0239-294a-5a1d-b4a4-f6348da2d01f","fields":{"slug":"2019-05-25"},"frontmatter":{"date":"2019-05-25","title":"2019-05-25","category":"blog","tags":["blog"],"banner":"/assets/bg/2.jpg"},"timeToRead":1},"next":{"excerpt":"skaffold 예제의 microservices example 스키마를 고쳐서 사용함.\n로 올리고 나서 gcp 포트 포워딩 후 웹 미리보기로 봤는데, 클라이언트가 통신 시도는 하는거 같은데 http https 섞여서 막힘. (클라이언트는 https://8080-... 이런 주소였고, 서버는 http). 그래서 인증서 설치하고 express에 https 적용하려고 openssl로 인증서를 만드려 했는데 뭔가 config file…","html":"<p>skaffold 예제의 microservices example 스키마를 고쳐서 사용함.\n<code class=\"language-text\">skaffold dev</code>로 올리고 나서 gcp 포트 포워딩 후 웹 미리보기로 봤는데, 클라이언트가 통신 시도는 하는거 같은데 http https 섞여서 막힘. (클라이언트는 <a href=\"https://8080-..\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://8080-..</a>. 이런 주소였고, 서버는 http). 그래서 인증서 설치하고 express에 https 적용하려고 openssl로 인증서를 만드려 했는데 뭔가 config file이 없다는 내용의 에러가 났다. <code class=\"language-text\">scoop which openssl</code>로 확인해 보니 <code class=\"language-text\">miniconda</code>의 openssl이었다. 다시 <code class=\"language-text\">scoop install openssl</code>로 설치한 후, openssl로 cert 만들어서 루트 폴더에 <code class=\"language-text\">cert</code>폴더를 만들고, 키와 cert파일을 넣고 도커파일에서 <code class=\"language-text\">COPY ../cert ./cert</code>이렇게 카피하려고 했더니 빌드 컨텍스트 밖이라며 에러가 났다. 그래서 좀 고민하다가, 알고보니 그냥 로드밸런서로 외부 노출해서 접속하면 클라이언트 주소가 https가 아니라 http여서 통신이 되었다. 그리고 제대로 검색까지 되었다. 드디어 클러스터 전체를 올린 것이다.</p>\n<p>이제 로드 밸런서로 노출된 클라이언트 주소를 aws 도메인이랑 연결하려고 했는데, 또 invalid host header가 뜨면서 실패했다. </p>\n<p><code class=\"language-text\">.env</code>파일에 HOST 환경 변수를 넣어서 <code class=\"language-text\">vocabo.epikem.com</code>로도 해보고, 로드 밸런서 주소로도 해보고, 포트 쌍도 <code class=\"language-text\">80</code>과 <code class=\"language-text\">3000</code> 두 가지로 네 조합을 다 돌려봤으나 전부 실패했다. open port를 찾을 수 없다거나,EADDRNOTAVAIL 이런 에러가 난다. <code class=\"language-text\">disableHostCheck</code> 아니면 직접 빌드하는것 밖에는 답이 없는걸까? 클라이언트를 빌드하고 <code class=\"language-text\">serve</code>로 웹 서비스를 제공하는 절차를 도커화 해야하려나? 그렇게 하면 연결이 되긴 할까? ~.~ 그리고 이렇게 하면 매 시도마다 빌드를 해야 해서 또 시간 깨나 먹을거 같은데.. 아니면 빌드해서 s3에 그냥 정적 페이지로 올려도 아마 될거같은데.</p>\n<p>어쩌면 <code class=\"language-text\">package.json</code>파일의 <code class=\"language-text\">homepage</code> 필드로 할 수 있는 부분이었을지도.</p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<p>  #vocabo, #cloud</p>","id":"3fc14800-f7ca-5461-9150-60da05de243a","fields":{"slug":"vocabo-cluster-동작-성공"},"frontmatter":{"date":"2019-05-27","title":"vocabo-cluster 동작 성공","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/2.jpg"},"timeToRead":1}}}