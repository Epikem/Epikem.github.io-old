{"pageContext":{"posts":[{"excerpt":"skaffold 예제의 microservices example 스키마를 고쳐서 사용함.\n 로 올리고 나서 gcp 포트 포워딩 후 웹 미리보기로 봤는데, 클라이언트가 통신 시도는 하는거 같은데 http https 섞여서 막힘. (클라이언트는  https://8080-.. . 이런 주소였고, 서버는 http). 그래서 인증서 설치하고 express에 https 적용하려고 openssl로 인증서를 만드려 했는데 뭔가 config file…","html":"<p>skaffold 예제의 microservices example 스키마를 고쳐서 사용함.\n<code class=\"language-text\">skaffold dev</code>로 올리고 나서 gcp 포트 포워딩 후 웹 미리보기로 봤는데, 클라이언트가 통신 시도는 하는거 같은데 http https 섞여서 막힘. (클라이언트는 <a href=\"https://8080-..\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://8080-..</a>. 이런 주소였고, 서버는 http). 그래서 인증서 설치하고 express에 https 적용하려고 openssl로 인증서를 만드려 했는데 뭔가 config file이 없다는 내용의 에러가 났다. <code class=\"language-text\">scoop which openssl</code>로 확인해 보니 <code class=\"language-text\">miniconda</code>의 openssl이었다. 다시 <code class=\"language-text\">scoop install openssl</code>로 설치한 후, openssl로 cert 만들어서 루트 폴더에 <code class=\"language-text\">cert</code>폴더를 만들고, 키와 cert파일을 넣고 도커파일에서 <code class=\"language-text\">COPY ../cert ./cert</code>이렇게 카피하려고 했더니 빌드 컨텍스트 밖이라며 에러가 났다. 그래서 좀 고민하다가, 알고보니 그냥 로드밸런서로 외부 노출해서 접속하면 클라이언트 주소가 https가 아니라 http여서 통신이 되었다. 그리고 제대로 검색까지 되었다. 드디어 클러스터 전체를 올린 것이다.</p>\n<p>이제 로드 밸런서로 노출된 클라이언트 주소를 aws 도메인이랑 연결하려고 했는데, 또 invalid host header가 뜨면서 실패했다. </p>\n<p><code class=\"language-text\">.env</code>파일에 HOST 환경 변수를 넣어서 <code class=\"language-text\">vocabo.epikem.com</code>로도 해보고, 로드 밸런서 주소로도 해보고, 포트 쌍도 <code class=\"language-text\">80</code>과 <code class=\"language-text\">3000</code> 두 가지로 네 조합을 다 돌려봤으나 전부 실패했다. open port를 찾을 수 없다거나,EADDRNOTAVAIL 이런 에러가 난다. <code class=\"language-text\">disableHostCheck</code> 아니면 직접 빌드하는것 밖에는 답이 없는걸까? 클라이언트를 빌드하고 <code class=\"language-text\">serve</code>로 웹 서비스를 제공하는 절차를 도커화 해야하려나? 그렇게 하면 연결이 되긴 할까? ~.~ 그리고 이렇게 하면 매 시도마다 빌드를 해야 해서 또 시간 깨나 먹을거 같은데.. 아니면 빌드해서 s3에 그냥 정적 페이지로 올려도 아마 될거같은데.</p>\n<p>어쩌면 <code class=\"language-text\">package.json</code>파일의 <code class=\"language-text\">homepage</code> 필드로 할 수 있는 부분이었을지도.</p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<p>  #vocabo, #cloud</p>","id":"3fc14800-f7ca-5461-9150-60da05de243a","fields":{"slug":"vocabo-cluster-동작-성공"},"frontmatter":{"date":"2019-05-27","title":"vocabo-cluster 동작 성공","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/2.jpg"},"timeToRead":1},{"excerpt":"에러가 나는게,  여기  설명에 나온대로 elasticsearch log를 확인해 보니, jaso analyzer 관련 클래스인  에서  에러가 나고 있었다. 들어가 코드를 확인해 보니, vscode에서  콜에서 매개변수가 안맞다며 빨간 줄이 쳐지고 quick fix를 하니 부모의 시그니쳐에 맞게 한 매개변수가 삭제되었다. 삭제하고 빌드해서 s3에 올리고 원래 설치된것 삭제하고 url…","html":"<p>에러가 나는게, <a href=\"https://docs.bitnami.com/google/apps/elasticsearch/get-started/understand-default-config/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">여기</a> 설명에 나온대로 elasticsearch log를 확인해 보니, jaso analyzer 관련 클래스인 <code class=\"language-text\">JasoTokenizerFactory</code>에서 <code class=\"language-text\">NoSuchMethod</code>에러가 나고 있었다. 들어가 코드를 확인해 보니, vscode에서 <code class=\"language-text\">super(...)</code>콜에서 매개변수가 안맞다며 빨간 줄이 쳐지고 quick fix를 하니 부모의 시그니쳐에 맞게 한 매개변수가 삭제되었다. 삭제하고 빌드해서 s3에 올리고 원래 설치된것 삭제하고 url로 다시 설치했는데 또 실패하길래 왜지 하다가 생각해보니 또 elasticsearch 서비스 재시작이 필요한 것이었다. 서비스 재시작을 하니 드디어 성공적으로 kengdic 인덱스를 만들었다. 아 그리고 매핑 타입이 없어졌다는걸 봐서 일단 'logs' 타입을 빼고 PUT 요청을 넣었다. 전에 쓰던 인덱스 세팅이 두 가지 있는데 뭐였는지 까먹었다. 아마도 아래꺼일듯.</p>\n<p>최종 요청 (아래꺼 씀.)</p>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\">PUT kengdic\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"analysis\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"nori-user-dict\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"decompound_mode\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"mixed\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"user_dictionary\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"userdict_ko.txt\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"analyzer-kor\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori-user-dict\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"analyzer-eng\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"lowercase\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    // <span class=\"token property\">\"logs\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"word\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-kor\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"def\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-eng\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    // <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\nPUT kengdic\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"analysis\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"suggest_filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"edge_ngram\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"min_gram\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"max_gram\"</span><span class=\"token operator\">:</span> <span class=\"token number\">50</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"nori-user-dict\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"decompound_mode\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"mixed\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"user_dictionary\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"userdict_ko.txt\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"jaso_search_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"jaso_index_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span>\n        <span class=\"token punctuation\">}</span>\n        // <span class=\"token property\">\"jaso_search_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        //   <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span>\n        // <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        // <span class=\"token property\">\"jaso_index_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        //   <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span>\n        // <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"analyzer-kor\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori-user-dict\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"analyzer-eng\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"lowercase\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"kor-suggest_search_analyzer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_search_tokenizer\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"kor-suggest_index_analyzer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_index_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"suggest_filter\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"logs\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"word\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"store\"</span><span class=\"token operator\">:</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"kor-suggest_index_analyzer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"search_analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"kor-suggest_search_analyzer\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"def\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-eng\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>그런데 데이터를 다 넣어도 <code class=\"language-text\">GET _stats</code>의 결과에서 kengdic의 document count가 0이길래 왜인가 싶어 로그를 확인했더니, <code class=\"language-text\">rejecting mapping update to as the final mapping would have more than 1 type [_doc, logs]</code> 이런 에러가 떴다. 생각해보니, elasticsearch 버전 7쯤에서 매핑 타입이 없어졌다지만, 나는 scoop으로 설치한 구버전 logstash를 그대로 쓰고있어서 type을 지정 안 하면 전처럼 <code class=\"language-text\">logs</code> 타입으로 기본으로 넣으려 한 것이다. 그래서 logstash 문서에서 찾아보니 elasticsearch output 플러그인에서는 <code class=\"language-text\">document_type</code>으로 지정하면 된다고 해서 <code class=\"language-text\">document_type=&gt;&quot;_doc&quot;</code>이렇게 하니 성공적으로 데이터가 들어가고 검색도 성공했다. 드디어!</p>\n<p>드디어 클러스터 전체를 테스트할 차례가 왔다. 문제는 어디 가거나 잘 때마다 이 전체 설정을 반복해야하는데.. bash 스크립트로 짜야 하려나?</p>\n<p>elasticsearch 서비스 생성 과정:</p>\n<ol>\n<li>elasticsearch cluster certified by bitnami를 배포.</li>\n<li>배포 완료되면 elasticsearch-vm에 접속</li>\n<li>vm에서 <code class=\"language-text\">jaso-analyzer</code>, <code class=\"language-text\">nori-analysis</code> 플러그인 설치. (<code class=\"language-text\">jaso-analyzer</code>는 aws s3에 올려놓고 퍼블릭으로 설정하면 주소로 바로 설치 가능.)</li>\n<li>vm에서 <code class=\"language-text\">sudo touch /opt/bitnami/elasticsearch/config/userdict_ko.txt</code> 로 사용자 사전 파일 생성</li>\n<li>vm에서 <code class=\"language-text\">sudo /opt/bitnami/ctlscript.sh restart elasticsearch</code>로 es 서비스 재시작(플러그인 로드)</li>\n<li>es 서비스가 재시작되었으면 <code class=\"language-text\">kengdic</code> 인덱스 생성하기.</li>\n<li>로컬에서 logstash의 elasticsearch output 필터의 <code class=\"language-text\">user</code>, <code class=\"language-text\">password</code> 항목을 위에서 생성한 클러스터의 정보를 참고하여 업데이트</li>\n<li><code class=\"language-text\">importDatas.ps1</code> 실행</li>\n</ol>\n<p>로컬과 구글 콘솔 gui와 원격 vm 환경이 조합되어있어 자동화가 어려워보인다.. gcp에서 현재 상태를 다시 docker image처럼 템플릿화해서 저장해둘 수 있으면 정말 좋겠다. </p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<p>  #vocabo, #elasticsearch</p>","id":"7567270a-d47e-5437-963d-72131458e5e1","fields":{"slug":"드디어-kengdic-index-생성-완료"},"frontmatter":{"date":"2019-05-26","title":"드디어!! kengdic index 생성 완료","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/3.jpg"},"timeToRead":2},{"excerpt":"역시 설치만 한다고 바로 적용될 리가 없었다. 서비스 재시작이 필요한 것.  bitnami 설명서 에 떡하니 서비스 관리 방법이 나와 있었다. ReadTheDocs +1.. 나중에 다시 설치해야할 경우를 위한 절차: jaso-analyzer 저장소에 올라와있는 빌드되어있는 패키지 다운로드. 압축을 풀어 버전을 현재 elasticsearch 버전으로 맞춘다 (추가 절차 있음) 다시 압축한다 aws s…","html":"<p>역시 설치만 한다고 바로 적용될 리가 없었다. 서비스 재시작이 필요한 것. <a href=\"https://docs.bitnami.com/google/apps/elasticsearch/administration/control-services/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">bitnami 설명서</a>에 떡하니 서비스 관리 방법이 나와 있었다. ReadTheDocs +1..</p>\n<p>나중에 다시 설치해야할 경우를 위한 절차:</p>\n<ol>\n<li>jaso-analyzer 저장소에 올라와있는 빌드되어있는 패키지 다운로드.</li>\n<li>압축을 풀어 버전을 현재 elasticsearch 버전으로 맞춘다 (추가 절차 있음)</li>\n<li>다시 압축한다</li>\n<li>aws s3에 올리고, 퍼블릭으로 설정한다</li>\n<li>elasticsearch vm 인스턴스에서 <code class=\"language-text\">wget</code>으로 다운로드한다</li>\n<li><code class=\"language-text\">elasticsearch-plugin install file://&lt;path-to-plugin&gt;</code> 명령어로 플러그인을 설치한다.</li>\n<li>공식 플러그인인 <code class=\"language-text\">nori-analyzer</code>의 경우, 그냥 <code class=\"language-text\">elasticsearch-plugin install analysis-nori</code>였나 여튼 이름으로 설치 가능하다.</li>\n<li><code class=\"language-text\">elasticsearch-plugin list</code>명령으로 설치가 되었는지 확인한다.</li>\n<li><code class=\"language-text\">nori-tokenizer</code>에서 사용자 사전을 쓸 경우 추가해줘야 할 수 있다.</li>\n<li>적용하려면 elasticsearch 서비스를 재시작 해야한다. 찾아보니 rolling update도 지원하긴 하는듯.</li>\n</ol>\n<p><code class=\"language-text\">anaylisys-nori</code>와 <code class=\"language-text\">jaso-analyzer</code>설치 후 재시작하고나서 아래 요청을 보내니 전과는 다른 에러가 떴다. 이제 <code class=\"language-text\">userdict</code>만 추가하면 될 것이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\">// Request\nPUT kengdic\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"analysis\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"nori-user-dict\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"decompound_mode\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"mixed\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"user_dictionary\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"userdict_ko.txt\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"analyzer-kor\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori-user-dict\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"analyzer-eng\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"lowercase\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"logs\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"word\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-kor\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"def\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-eng\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n// Response\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"error\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"root_cause\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n      <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"illegal_argument_exception\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"reason\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"IOException while reading user_dictionary: /opt/bitnami/elasticsearch/config/userdict_ko.txt\"</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"illegal_argument_exception\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"reason\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"IOException while reading user_dictionary: /opt/bitnami/elasticsearch/config/userdict_ko.txt\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"caused_by\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"no_such_file_exception\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"reason\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"/opt/bitnami/elasticsearch/config/userdict_ko.txt\"</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"status\"</span><span class=\"token operator\">:</span> <span class=\"token number\">400</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>고치고 나서 하면 바로 성공할 줄 알았는데, 이런 에러가 뜬다.</p>\n<div class=\"gatsby-highlight\" data-language=\"html\"><pre class=\"language-html\"><code class=\"language-html\"><span class=\"token doctype\">&lt;!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>html</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>head</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>title</span><span class=\"token punctuation\">></span></span>502 Proxy Error<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>title</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>head</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>body</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>h1</span><span class=\"token punctuation\">></span></span>Proxy Error<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>h1</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>p</span><span class=\"token punctuation\">></span></span>The proxy server received an invalid\nresponse from an upstream server.<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>br</span> <span class=\"token punctuation\">/></span></span>\nThe proxy server could not handle the request <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>em</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>a</span> <span class=\"token attr-name\">href</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>/elasticsearch/kengdic<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>PUT<span class=\"token entity\" title=\"&nbsp;\">&amp;nbsp;</span>/elasticsearch/kengdic<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>a</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>em</span><span class=\"token punctuation\">></span></span>.<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>p</span><span class=\"token punctuation\">></span></span>\nReason: <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>strong</span><span class=\"token punctuation\">></span></span>Error reading from remote server<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>strong</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>p</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>p</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>body</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>html</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<p>d아마도ㅡ\n7.0.1로 버전이 올라가면서 스키마 자체가 바뀌어서일 수 있겠다.</p>\n<p>확실히 이쪽이 맞는듯.</p>\n<p><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/6.7/removal-of-types.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.elastic.co/guide/en/elasticsearch/reference/6.7/removal-of-types.html</a>\n<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/7.x/breaking-changes-7.0.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.elastic.co/guide/en/elasticsearch/reference/7.x/breaking-changes-7.0.html</a></p>\n<h2 id=\"installing-elasticsearch-plugins\"><a href=\"#installing-elasticsearch-plugins\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>installing-elasticsearch-plugins</h2>\n<p><code class=\"language-text\">elasticsearch-plugin</code> cli를 이용하여 설치 후, elasticsearch 서비스를 재시작한다.</p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<p>  #TIL, #elasticsearch</p>","id":"da0eda94-016e-5cfd-9344-952d67735f2b","fields":{"slug":"드디어-bitnami-certified-elasticsearch-플러그인-인스톨-문제-알아냄"},"frontmatter":{"date":"2019-05-25","title":"드디어! bitnami certified elasticsearch 플러그인 인스톨 문제 알아냄","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/1.jpg"},"timeToRead":2},{"excerpt":"쿠버네티스에서 막힌 상태. 설정이 어려워서 그냥 거의 복붙하다시피 해야할듯. 제대로 쿠버네티스 설정을 해서 gcp에 올려보아야 겠다. 현재 단어장 업데이트 기능은 없이 elastic과 server, client 이 세 개의 컨테이너만 돌리면 되는데, 자꾸 업로드해도 에러가 나서 하질 못하고 있었다. 정말 그냥 자원이 모자라서였는지 아니면 설정이 잘못된건지 (liveness check…","html":"<p>쿠버네티스에서 막힌 상태. 설정이 어려워서 그냥 거의 복붙하다시피 해야할듯.</p>\n<p>제대로 쿠버네티스 설정을 해서 gcp에 올려보아야 겠다.</p>\n<p>현재 단어장 업데이트 기능은 없이 elastic과 server, client 이 세 개의 컨테이너만 돌리면 되는데, 자꾸 업로드해도 에러가 나서 하질 못하고 있었다. 정말 그냥 자원이 모자라서였는지 아니면 설정이 잘못된건지 (liveness check 등) 알아야 한다.</p>\n<p>수정해야 할 부분:</p>\n<ol>\n<li>쿠버네티스에서 client와 server연결</li>\n</ol>\n<p>client에서 <code class=\"language-text\">/en/query</code> 이런식으로 요청하는데, 그러면 같은 포트를 쓰게 해도 되는건가? 겹치면 문제가 되지 않나? 그리고 쿠버네티스 노드 포트와 클러스터 ip가 각각 어떻게 동작하는건지 모르겠다. 그리고 포트와 대상 포트의 의미도 모르겠다. 분명 들어오는 포트와 내부에서 연결되는 포트를 다르게 하게 위해 필요한 기능같은데, 물음표 설명을 봐도 뭔소린지 이해가 안 된다.</p>\n<p>성능 높이니 클라이언트는 돌아가는게 확인이 되었는데, 서버랑 연결이 안 되고 있는 것으로 보인다.</p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<ul>\n<li>#vocabo, #kubernetes, #blog</li>\n</ul>","id":"2290e5ed-29b1-53ce-ade9-13d7a974d0a6","fields":{"slug":"vocabo-개발-상황"},"frontmatter":{"date":"2019-04-17","title":"vocabo 개발 상황","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/1.jpg"},"timeToRead":1}],"tagName":"project/vocabo"}}