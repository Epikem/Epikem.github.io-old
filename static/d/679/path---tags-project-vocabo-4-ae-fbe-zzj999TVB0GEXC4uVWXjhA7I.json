{"pageContext":{"posts":[{"excerpt":"elasticsearch 버전 및 elk stack by bitnami 및 logstash가 전부 조금씩 바뀌면서 손을 봐줘야 하게 되었다.이전에 하던 대로 elk certified by bitnami를 쓰려 했는데 compute instance에 ssh로 접속하려 하니 passphrase를 적으라는데, 어디서 그걸 찾을 수 있는지 몰라서 한참 찾다가, 다 삭제하고 bitnami…","html":"<p>elasticsearch 버전 및 elk stack by bitnami 및 logstash가 전부 조금씩 바뀌면서 손을 봐줘야 하게 되었다.</p>\n<ol>\n<li>이전에 하던 대로 elk certified by bitnami를 쓰려 했는데 compute instance에 ssh로 접속하려 하니 passphrase를 적으라는데, 어디서 그걸 찾을 수 있는지 몰라서 한참 찾다가, 다 삭제하고 bitnami 사이트에서 자체 스택 만들기 기능으로 스택을 만들고 나서야 찾을 수 있었다.</li>\n<li>elasticsearch 버전이 7.3.2가 되어서 jaso-analyzer 버전 숫자도 그에 맞게 높여줬다. 제대로 작동할지는 모르겠다.</li>\n<li>elasticsearch 매핑 부분이 조금 바뀌어서, \"logs\"인덱스 이름/타입 이름?을 빼주고 나서야 put 요청이 성공했다.</li>\n<li>그랬더니, 이번엔 logstash에서 template file을 못찾는다는 에러가 떴다. 찾아보니 mapping 형식을 json으로 나타낸 것을 의미하는거 같은데, 그걸 왜 또 중복으로 적어야 하나? 버전 차이 때문인가 싶어서 logstash를 업데이트하려고 했는데, checkver부분이 달라져서인지 scoop에서 버전 업데이트가 되지 않고 있었다. 그래서 어쩔 수 없이 그냥 직접 받은 다음 테스트 하기로 했다.</li>\n<li>알고보니 logstash 바뀐 부분이, 절대 경로를 써야한다고 한다. 그래서 파일이 제대로 안 읽히고 있었던 것.\n고치니까 데이터가 들어갔다. 근데 너무나 느려서 확인해보니 stdout{} 플러그인 출력때문에 느려서 그걸 지우고 하니 훨씬 빨라졌다.</li>\n<li>\n<p>드디어 데이터를 다 올리고, 서버를 올릴 차례다. 먼저 server에서 deconfig 이후 config 명령으로, 파라미터를 아래와 같이 주어서 세팅을 해야 한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"ps\"><pre class=\"language-ps\"><code class=\"language-ps\">npm run config -- --account-id=014553383153 --bucket-name=vocabo-lambda-bucket --function-name=vocaboServer --region=ap-northeast-2</code></pre></div>\n<p>처음에 --region 플래그 없이 했을때 왜 스택이 만들어졌다는데 안뜨지? 했는데 버지니아 북부 (기본 region)에 만들어지고 있었던 거였다.</p>\n</li>\n<li><code class=\"language-text\">win-package-deploy</code> 명령으로 스택을 만들고 이제 rest api경로에서 테스트해보는데 기본 경로는 forbidden이 뜨고, prod 스테이지 경로는 타임아웃이 뜨길래 왜인가 했는데, lambda 환경 변수 설정이 잘못되어 있었다. </li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">ELASTICSEARCH_URL: http://&lt;userid&gt;:&lt;password&gt;@35.229.203.172:80/elasticsearch/</code></pre></div>\n<p>이렇게 되어있어야 하는데,</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">ELASTICSEARCH_URL: http://&lt;userid&gt;:&lt;password&gt;@http://35.229.203.172:80/elasticsearch/</code></pre></div>\n<p>이렇게 되어 있었음.\n고치니까 prod 스테이지 경로에서 잘 작동이 되는것을 확인할 수 있었다. 그리고 사이트에서도 동작이 되었다.\n여전히 영어 검색시 5개만 보여주는걸 고치지 못했지만.</p>\n<ol start=\"8\">\n<li>비용절감을 위해 compute 인스턴스를 멈춘 다음 사이즈 조절을 했는데, bitnami에서 그 정보는 동기화가 안 된다. 그리고, bitnami를 써서 재시작해야 제대로 서비스들이 돌아가는것 같다(확인 필요). 또, ip도 바뀌므로 서버쪽도 재업로드 해야한다.</li>\n</ol>\n<p>aws는 학생 크레딧을 년마다 준다는데, 구글은 아직 안 되는 모양이다. 가능하면 elasticsearch만 aws로 옮길 수 있다면 더 이상 gcp를 쓸 이유가 없으므로 그쪽을 고려해보아야겠다.</p>\n<p>유저 요청이 있을 때만 서버 서비스 스택을 잠시 만드는 식으로 하면 좋을거 같은데. 상당히 고려할 게 많다.</p>","id":"a48d6e05-b4b9-5146-8e60-158bb0f3459d","fields":{"slug":"vocabo-server-재배포-시도"},"frontmatter":{"date":"2019-10-01","title":"vocabo-server 재배포 시도","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/4.jpg"},"timeToRead":2},{"excerpt":"aws Lambda로 전환 완료, https 적용 및 react devtools버그 해결(크롬 렌더링 문제).aws Lambda로 에 서버를 올렸는데 에러가 난 이유를 못찾아서 로그를 어디서 찾나 했는데 aws Lambda 다이어그램에서 확인해보니 aws CloudWatch에 기록되고 있었다. 로그를 확인해 보니 app.js 파일 1…","html":"<p>aws Lambda로 전환 완료, https 적용 및 react devtools버그 해결(크롬 렌더링 문제).</p>\n<p>aws Lambda로 <code class=\"language-text\">vocabo-api.epikem.com</code>에 서버를 올렸는데 에러가 난 이유를 못찾아서 로그를 어디서 찾나 했는데 aws Lambda 다이어그램에서 확인해보니 aws CloudWatch에 기록되고 있었다. 로그를 확인해 보니 app.js 파일 15번째 줄에서 컴파일 에러가 났는데, <code class=\"language-text\">new URL(&#39;...&#39;)</code> 부분이었다. 노드에서는 직접 <code class=\"language-text\">url</code> 모듈을 로드하지 않아도 코드가 돌아갔었는데, 람다에서는 로드를 해야하는 것이었다. 다음과 같이 <code class=\"language-text\">url</code>모듈의 <code class=\"language-text\">URL</code>을 로드하여 사용하니 이 부분은 해결되었다.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\"><span class=\"token keyword\">const</span> <span class=\"token punctuation\">{</span> <span class=\"token constant\">URL</span> <span class=\"token punctuation\">}</span> <span class=\"token operator\">=</span> <span class=\"token function\">require</span><span class=\"token punctuation\">(</span><span class=\"token string\">'url'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>다시 패키지 빌드 및 배포를 시도하니 이번엔 url이 잘못됬다는 에러가 떴는데, 예상한 대로 환경변수 문제였다. <code class=\"language-text\">.env</code>파일 추가로는 람다 패키지 추가가 되지 않았고, 다행히 AWS CloudFormation 공식문서에서 Lambda에 환경변수를 설정하는 방법을 찾아 다음과 같이 채운 다음 다시 배포하니 성공적으로 api 서버가 등록되었다. 드디어 https 및 커스텀 도메인이 적용된 api 서버를 만들었다. 게다가 호출한 만큼만 사용되므로 절약까지 된다. 다만 클라우드 저장소는 결국 샘플에서 수정만 한 것인데, 직접 이런 템플릿을 짜라 하면 도저히 못 할거 같은 느낌이 든다.. (하지만 이건 aws&#x26;cloudformation 쪽이니 모르는게 당연한 것이다)</p>\n<p>file: cloudformation.yaml</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">vocaboLambda</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">...</span>\n  <span class=\"token key atrule\">Properties</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">...</span>\n    <span class=\"token key atrule\">Environment</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">Variables</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">ELASTIC_URL</span><span class=\"token punctuation\">:</span> (value)\n<span class=\"token punctuation\">...</span></code></pre></div>\n<p>api gateway에서 요청량 제한하니 진짜 제한되는것이 신기하다.</p>\n<p>이상한게, 여전히 프론트가 모바일에서 안 뜨길래 찾아봤더니, react <code class=\"language-text\">BrowserHistory</code>사용이 문제가 될 수 있으므로 <code class=\"language-text\">HashHistory</code>를 쓰라는  글이 있었지만, 분명 데스크탑에서는 잘 떴기 때문에 이게 원인이 아니라고 생각했는데 정말이었다. 알고보니 데스크탑 크롬에서도 표시가 안 되었고, 콘솔을 보니 <code class=\"language-text\">website.reduxDevTools</code>가 없다는 에러가 표시되고 있었다. deprecate된다는 걸 전부터 보긴 했는데 아예 없앤것이거나, 설치가 안됬을때에 대한 코드 커버가 안되있거나 한거같은데, 그냥 귀찮아서 <code class=\"language-text\">redux-devtools-extension</code> 패키지를 설치해서 적용하여 해결했다.</p>\n<p>이제 모바일도 잘 들어가진다. 다만 반응형이라기엔 아쉬운 상태.</p>\n<p>할 것:</p>\n<ul>\n<li>반응형</li>\n<li>영어 검색 개선 (같은 단어 합치기)</li>\n<li>영어 검색시 5개에서 여러개로 늘리기</li>\n<li>회원 및 개인 단어장 기능. 이거 하려면 또 한 세월 걸릴 듯.</li>\n</ul>\n<p>등..</p>\n<p>그런데 이대로 <code class=\"language-text\">test2-backup</code> 브랜치를 진행해버리면 히스토리가 너무 더러워져버린다.</p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<p>  #vocabo, #cloud, #aws, #aws</p>","id":"70f6e6da-f9ad-536f-b1b3-01b71d96d337","fields":{"slug":"vocabo-배포-마무리"},"frontmatter":{"date":"2019-05-31","title":"vocabo 배포 마무리","category":"vocabo","tags":["project/vocabo","dev/cloud","dev/cloud/aws","dev/cloud/aws"],"banner":"/assets/bg/2.jpg"},"timeToRead":1},{"excerpt":"skaffold 예제의 microservices example 스키마를 고쳐서 사용함.\n로 올리고 나서 gcp 포트 포워딩 후 웹 미리보기로 봤는데, 클라이언트가 통신 시도는 하는거 같은데 http https 섞여서 막힘. (클라이언트는 https://8080-... 이런 주소였고, 서버는 http). 그래서 인증서 설치하고 express에 https 적용하려고 openssl로 인증서를 만드려 했는데 뭔가 config file…","html":"<p>skaffold 예제의 microservices example 스키마를 고쳐서 사용함.\n<code class=\"language-text\">skaffold dev</code>로 올리고 나서 gcp 포트 포워딩 후 웹 미리보기로 봤는데, 클라이언트가 통신 시도는 하는거 같은데 http https 섞여서 막힘. (클라이언트는 <a href=\"https://8080-..\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://8080-..</a>. 이런 주소였고, 서버는 http). 그래서 인증서 설치하고 express에 https 적용하려고 openssl로 인증서를 만드려 했는데 뭔가 config file이 없다는 내용의 에러가 났다. <code class=\"language-text\">scoop which openssl</code>로 확인해 보니 <code class=\"language-text\">miniconda</code>의 openssl이었다. 다시 <code class=\"language-text\">scoop install openssl</code>로 설치한 후, openssl로 cert 만들어서 루트 폴더에 <code class=\"language-text\">cert</code>폴더를 만들고, 키와 cert파일을 넣고 도커파일에서 <code class=\"language-text\">COPY ../cert ./cert</code>이렇게 카피하려고 했더니 빌드 컨텍스트 밖이라며 에러가 났다. 그래서 좀 고민하다가, 알고보니 그냥 로드밸런서로 외부 노출해서 접속하면 클라이언트 주소가 https가 아니라 http여서 통신이 되었다. 그리고 제대로 검색까지 되었다. 드디어 클러스터 전체를 올린 것이다.</p>\n<p>이제 로드 밸런서로 노출된 클라이언트 주소를 aws 도메인이랑 연결하려고 했는데, 또 invalid host header가 뜨면서 실패했다. </p>\n<p><code class=\"language-text\">.env</code>파일에 HOST 환경 변수를 넣어서 <code class=\"language-text\">vocabo.epikem.com</code>로도 해보고, 로드 밸런서 주소로도 해보고, 포트 쌍도 <code class=\"language-text\">80</code>과 <code class=\"language-text\">3000</code> 두 가지로 네 조합을 다 돌려봤으나 전부 실패했다. open port를 찾을 수 없다거나,EADDRNOTAVAIL 이런 에러가 난다. <code class=\"language-text\">disableHostCheck</code> 아니면 직접 빌드하는것 밖에는 답이 없는걸까? 클라이언트를 빌드하고 <code class=\"language-text\">serve</code>로 웹 서비스를 제공하는 절차를 도커화 해야하려나? 그렇게 하면 연결이 되긴 할까? ~.~ 그리고 이렇게 하면 매 시도마다 빌드를 해야 해서 또 시간 깨나 먹을거 같은데.. 아니면 빌드해서 s3에 그냥 정적 페이지로 올려도 아마 될거같은데.</p>\n<p>어쩌면 <code class=\"language-text\">package.json</code>파일의 <code class=\"language-text\">homepage</code> 필드로 할 수 있는 부분이었을지도.</p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<p>  #vocabo, #cloud</p>","id":"3fc14800-f7ca-5461-9150-60da05de243a","fields":{"slug":"vocabo-cluster-동작-성공"},"frontmatter":{"date":"2019-05-27","title":"vocabo-cluster 동작 성공","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/2.jpg"},"timeToRead":1},{"excerpt":"에러가 나는게, 여기 설명에 나온대로 elasticsearch log를 확인해 보니, jaso analyzer 관련 클래스인 에서 에러가 나고 있었다. 들어가 코드를 확인해 보니, vscode에서 콜에서 매개변수가 안맞다며 빨간 줄이 쳐지고 quick fix를 하니 부모의 시그니쳐에 맞게 한 매개변수가 삭제되었다. 삭제하고 빌드해서 s3에 올리고 원래 설치된것 삭제하고 url…","html":"<p>에러가 나는게, <a href=\"https://docs.bitnami.com/google/apps/elasticsearch/get-started/understand-default-config/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">여기</a> 설명에 나온대로 elasticsearch log를 확인해 보니, jaso analyzer 관련 클래스인 <code class=\"language-text\">JasoTokenizerFactory</code>에서 <code class=\"language-text\">NoSuchMethod</code>에러가 나고 있었다. 들어가 코드를 확인해 보니, vscode에서 <code class=\"language-text\">super(...)</code>콜에서 매개변수가 안맞다며 빨간 줄이 쳐지고 quick fix를 하니 부모의 시그니쳐에 맞게 한 매개변수가 삭제되었다. 삭제하고 빌드해서 s3에 올리고 원래 설치된것 삭제하고 url로 다시 설치했는데 또 실패하길래 왜지 하다가 생각해보니 또 elasticsearch 서비스 재시작이 필요한 것이었다. 서비스 재시작을 하니 드디어 성공적으로 kengdic 인덱스를 만들었다. 아 그리고 매핑 타입이 없어졌다는걸 봐서 일단 'logs' 타입을 빼고 PUT 요청을 넣었다. 전에 쓰던 인덱스 세팅이 두 가지 있는데 뭐였는지 까먹었다. 아마도 아래꺼일듯.</p>\n<p>최종 요청 (아래꺼 씀.)</p>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\">PUT kengdic\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"analysis\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"nori-user-dict\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"decompound_mode\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"mixed\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"user_dictionary\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"userdict_ko.txt\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"analyzer-kor\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori-user-dict\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"analyzer-eng\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"lowercase\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    // <span class=\"token property\">\"logs\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"word\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-kor\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"def\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-eng\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    // <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\nPUT kengdic\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"analysis\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"suggest_filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"edge_ngram\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"min_gram\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"max_gram\"</span><span class=\"token operator\">:</span> <span class=\"token number\">50</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"nori-user-dict\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"decompound_mode\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"mixed\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"user_dictionary\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"userdict_ko.txt\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"jaso_search_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"jaso_index_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span>\n        <span class=\"token punctuation\">}</span>\n        // <span class=\"token property\">\"jaso_search_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        //   <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span>\n        // <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        // <span class=\"token property\">\"jaso_index_tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        //   <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"mistype\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n        //   <span class=\"token property\">\"chosung\"</span><span class=\"token operator\">:</span> <span class=\"token boolean\">true</span>\n        // <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"analyzer-kor\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori-user-dict\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"analyzer-eng\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"lowercase\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"kor-suggest_search_analyzer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_search_tokenizer\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"kor-suggest_index_analyzer\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"jaso_index_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"suggest_filter\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"logs\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"word\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"store\"</span><span class=\"token operator\">:</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"kor-suggest_index_analyzer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"search_analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"kor-suggest_search_analyzer\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"def\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-eng\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>그런데 데이터를 다 넣어도 <code class=\"language-text\">GET _stats</code>의 결과에서 kengdic의 document count가 0이길래 왜인가 싶어 로그를 확인했더니, <code class=\"language-text\">rejecting mapping update to as the final mapping would have more than 1 type [_doc, logs]</code> 이런 에러가 떴다. 생각해보니, elasticsearch 버전 7쯤에서 매핑 타입이 없어졌다지만, 나는 scoop으로 설치한 구버전 logstash를 그대로 쓰고있어서 type을 지정 안 하면 전처럼 <code class=\"language-text\">logs</code> 타입으로 기본으로 넣으려 한 것이다. 그래서 logstash 문서에서 찾아보니 elasticsearch output 플러그인에서는 <code class=\"language-text\">document_type</code>으로 지정하면 된다고 해서 <code class=\"language-text\">document_type=&gt;&quot;_doc&quot;</code>이렇게 하니 성공적으로 데이터가 들어가고 검색도 성공했다. 드디어!</p>\n<p>드디어 클러스터 전체를 테스트할 차례가 왔다. 문제는 어디 가거나 잘 때마다 이 전체 설정을 반복해야하는데.. bash 스크립트로 짜야 하려나?</p>\n<p>elasticsearch 서비스 생성 과정:</p>\n<ol>\n<li>elasticsearch cluster certified by bitnami를 배포.</li>\n<li>배포 완료되면 elasticsearch-vm에 접속</li>\n<li>vm에서 <code class=\"language-text\">jaso-analyzer</code>, <code class=\"language-text\">nori-analysis</code> 플러그인 설치. (<code class=\"language-text\">jaso-analyzer</code>는 aws s3에 올려놓고 퍼블릭으로 설정하면 주소로 바로 설치 가능.)</li>\n<li>vm에서 <code class=\"language-text\">sudo touch /opt/bitnami/elasticsearch/config/userdict_ko.txt</code> 로 사용자 사전 파일 생성</li>\n<li>vm에서 <code class=\"language-text\">sudo /opt/bitnami/ctlscript.sh restart elasticsearch</code>로 es 서비스 재시작(플러그인 로드)</li>\n<li>es 서비스가 재시작되었으면 <code class=\"language-text\">kengdic</code> 인덱스 생성하기.</li>\n<li>로컬에서 logstash의 elasticsearch output 필터의 <code class=\"language-text\">user</code>, <code class=\"language-text\">password</code> 항목을 위에서 생성한 클러스터의 정보를 참고하여 업데이트</li>\n<li><code class=\"language-text\">importDatas.ps1</code> 실행</li>\n</ol>\n<p>로컬과 구글 콘솔 gui와 원격 vm 환경이 조합되어있어 자동화가 어려워보인다.. gcp에서 현재 상태를 다시 docker image처럼 템플릿화해서 저장해둘 수 있으면 정말 좋겠다. </p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<p>  #vocabo, #elasticsearch</p>","id":"7567270a-d47e-5437-963d-72131458e5e1","fields":{"slug":"드디어-kengdic-index-생성-완료"},"frontmatter":{"date":"2019-05-26","title":"드디어!! kengdic index 생성 완료","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/3.jpg"},"timeToRead":2},{"excerpt":"역시 설치만 한다고 바로 적용될 리가 없었다. 서비스 재시작이 필요한 것. bitnami 설명서에 떡하니 서비스 관리 방법이 나와 있었다. ReadTheDocs +1..나중에 다시 설치해야할 경우를 위한 절차:jaso-analyzer 저장소에 올라와있는 빌드되어있는 패키지 다운로드.압축을 풀어 버전을 현재 elasticsearch 버전으로 맞춘다 (추가 절차 있음)다시 압축한다aws s3에 올리고, 퍼블릭으로 설정한다elasticsearch…","html":"<p>역시 설치만 한다고 바로 적용될 리가 없었다. 서비스 재시작이 필요한 것. <a href=\"https://docs.bitnami.com/google/apps/elasticsearch/administration/control-services/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">bitnami 설명서</a>에 떡하니 서비스 관리 방법이 나와 있었다. ReadTheDocs +1..</p>\n<p>나중에 다시 설치해야할 경우를 위한 절차:</p>\n<ol>\n<li>jaso-analyzer 저장소에 올라와있는 빌드되어있는 패키지 다운로드.</li>\n<li>압축을 풀어 버전을 현재 elasticsearch 버전으로 맞춘다 (추가 절차 있음)</li>\n<li>다시 압축한다</li>\n<li>aws s3에 올리고, 퍼블릭으로 설정한다</li>\n<li>elasticsearch vm 인스턴스에서 <code class=\"language-text\">wget</code>으로 다운로드한다</li>\n<li><code class=\"language-text\">elasticsearch-plugin install file://&lt;path-to-plugin&gt;</code> 명령어로 플러그인을 설치한다.</li>\n<li>공식 플러그인인 <code class=\"language-text\">nori-analyzer</code>의 경우, 그냥 <code class=\"language-text\">elasticsearch-plugin install analysis-nori</code>였나 여튼 이름으로 설치 가능하다.</li>\n<li><code class=\"language-text\">elasticsearch-plugin list</code>명령으로 설치가 되었는지 확인한다.</li>\n<li><code class=\"language-text\">nori-tokenizer</code>에서 사용자 사전을 쓸 경우 추가해줘야 할 수 있다.</li>\n<li>적용하려면 elasticsearch 서비스를 재시작 해야한다. 찾아보니 rolling update도 지원하긴 하는듯.</li>\n</ol>\n<p><code class=\"language-text\">anaylisys-nori</code>와 <code class=\"language-text\">jaso-analyzer</code>설치 후 재시작하고나서 아래 요청을 보내니 전과는 다른 에러가 떴다. 이제 <code class=\"language-text\">userdict</code>만 추가하면 될 것이다.</p>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\">// Request\nPUT kengdic\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"settings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"analysis\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"nori-user-dict\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori_tokenizer\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"decompound_mode\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"mixed\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"user_dictionary\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"userdict_ko.txt\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"analyzer-kor\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"nori-user-dict\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"analyzer-eng\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"custom\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"tokenizer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"standard\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"filter\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n            <span class=\"token string\">\"lowercase\"</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"mappings\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"logs\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"properties\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"word\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-kor\"</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"def\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n          // <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"completion\"</span><span class=\"token punctuation\">,</span>\n          <span class=\"token property\">\"analyzer\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"analyzer-eng\"</span>\n        <span class=\"token punctuation\">}</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n// Response\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"error\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token property\">\"root_cause\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n      <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"illegal_argument_exception\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"reason\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"IOException while reading user_dictionary: /opt/bitnami/elasticsearch/config/userdict_ko.txt\"</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"illegal_argument_exception\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"reason\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"IOException while reading user_dictionary: /opt/bitnami/elasticsearch/config/userdict_ko.txt\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token property\">\"caused_by\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"no_such_file_exception\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token property\">\"reason\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"/opt/bitnami/elasticsearch/config/userdict_ko.txt\"</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"status\"</span><span class=\"token operator\">:</span> <span class=\"token number\">400</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>고치고 나서 하면 바로 성공할 줄 알았는데, 이런 에러가 뜬다.</p>\n<div class=\"gatsby-highlight\" data-language=\"html\"><pre class=\"language-html\"><code class=\"language-html\"><span class=\"token doctype\">&lt;!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>html</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>head</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>title</span><span class=\"token punctuation\">></span></span>502 Proxy Error<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>title</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>head</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>body</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>h1</span><span class=\"token punctuation\">></span></span>Proxy Error<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>h1</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>p</span><span class=\"token punctuation\">></span></span>The proxy server received an invalid\nresponse from an upstream server.<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>br</span> <span class=\"token punctuation\">/></span></span>\nThe proxy server could not handle the request <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>em</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>a</span> <span class=\"token attr-name\">href</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>/elasticsearch/kengdic<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>PUT<span class=\"token entity\" title=\"&nbsp;\">&amp;nbsp;</span>/elasticsearch/kengdic<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>a</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>em</span><span class=\"token punctuation\">></span></span>.<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>p</span><span class=\"token punctuation\">></span></span>\nReason: <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>strong</span><span class=\"token punctuation\">></span></span>Error reading from remote server<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>strong</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>p</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>p</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>body</span><span class=\"token punctuation\">></span></span><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>html</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<p>d아마도ㅡ\n7.0.1로 버전이 올라가면서 스키마 자체가 바뀌어서일 수 있겠다.</p>\n<p>확실히 이쪽이 맞는듯.</p>\n<p><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/6.7/removal-of-types.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.elastic.co/guide/en/elasticsearch/reference/6.7/removal-of-types.html</a>\n<a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/7.x/breaking-changes-7.0.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.elastic.co/guide/en/elasticsearch/reference/7.x/breaking-changes-7.0.html</a></p>\n<h2 id=\"installing-elasticsearch-plugins\"><a href=\"#installing-elasticsearch-plugins\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>installing-elasticsearch-plugins</h2>\n<p><code class=\"language-text\">elasticsearch-plugin</code> cli를 이용하여 설치 후, elasticsearch 서비스를 재시작한다.</p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<p>  #TIL, #elasticsearch</p>","id":"da0eda94-016e-5cfd-9344-952d67735f2b","fields":{"slug":"드디어-bitnami-certified-elasticsearch-플러그인-인스톨-문제-알아냄"},"frontmatter":{"date":"2019-05-25","title":"드디어! bitnami certified elasticsearch 플러그인 인스톨 문제 알아냄","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/1.jpg"},"timeToRead":2},{"excerpt":"쿠버네티스에서 막힌 상태. 설정이 어려워서 그냥 거의 복붙하다시피 해야할듯.제대로 쿠버네티스 설정을 해서 gcp에 올려보아야 겠다.현재 단어장 업데이트 기능은 없이 elastic과 server, client 이 세 개의 컨테이너만 돌리면 되는데, 자꾸 업로드해도 에러가 나서 하질 못하고 있었다. 정말 그냥 자원이 모자라서였는지 아니면 설정이 잘못된건지 (liveness check 등) 알아야 한다.수정해야 할 부분:쿠버네티스에서 client…","html":"<p>쿠버네티스에서 막힌 상태. 설정이 어려워서 그냥 거의 복붙하다시피 해야할듯.</p>\n<p>제대로 쿠버네티스 설정을 해서 gcp에 올려보아야 겠다.</p>\n<p>현재 단어장 업데이트 기능은 없이 elastic과 server, client 이 세 개의 컨테이너만 돌리면 되는데, 자꾸 업로드해도 에러가 나서 하질 못하고 있었다. 정말 그냥 자원이 모자라서였는지 아니면 설정이 잘못된건지 (liveness check 등) 알아야 한다.</p>\n<p>수정해야 할 부분:</p>\n<ol>\n<li>쿠버네티스에서 client와 server연결</li>\n</ol>\n<p>client에서 <code class=\"language-text\">/en/query</code> 이런식으로 요청하는데, 그러면 같은 포트를 쓰게 해도 되는건가? 겹치면 문제가 되지 않나? 그리고 쿠버네티스 노드 포트와 클러스터 ip가 각각 어떻게 동작하는건지 모르겠다. 그리고 포트와 대상 포트의 의미도 모르겠다. 분명 들어오는 포트와 내부에서 연결되는 포트를 다르게 하게 위해 필요한 기능같은데, 물음표 설명을 봐도 뭔소린지 이해가 안 된다.</p>\n<p>성능 높이니 클라이언트는 돌아가는게 확인이 되었는데, 서버랑 연결이 안 되고 있는 것으로 보인다.</p>\n<h2 id=\"tags\"><a href=\"#tags\" aria-hidden class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>tags</h2>\n<ul>\n<li>#vocabo, #kubernetes, #blog</li>\n</ul>","id":"2290e5ed-29b1-53ce-ade9-13d7a974d0a6","fields":{"slug":"vocabo-개발-상황"},"frontmatter":{"date":"2019-04-17","title":"vocabo 개발 상황","category":"vocabo","tags":["project/vocabo"],"banner":"/assets/bg/1.jpg"},"timeToRead":1}],"tagName":"project/vocabo"}}